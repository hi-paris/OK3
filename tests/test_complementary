"""
Complementary testing for OK3
"""
import pytest
from sklearn.datasets import load_diabetes
from _classes import OK3Regressor
from _classes import ExtraOK3Regressor
import time
from sklearn.model_selection import train_test_split
from sklearn.utils.validation import check_is_fitted, check_X_y
from sklearn.exceptions import NotFittedError
from sklearn.metrics import mean_squared_error as MSE
#from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score
#from sklearn.utils.estimator_checks import check_estimator
import numpy as np

#Estimators to check
OKTREES = {
    "OK3Regressor": OK3Regressor,
    "ExtraOK3Regressor": ExtraOK3Regressor
}

#Datasets used
X, y = load_diabetes(return_X_y=True)

#Validation of the datasets
def test_X_y():
    """Input validation for standard estimators.

    Checks X and y for consistent length, enforces X to be 2D and y 1D.
    By default, X is checked to be non-empty and containing only finite values.
    Standard input checks are also applied to y,
    such as checking that y does not have np.nan or np.inf targets.

    Returns
    -------
    None
    """
    check_X_y(X, y)

def fitted_predicted_OK3(X, y, Tree):
    """Function running OK3 and returning Y_train, Y_test, and Y_preds, for readability purposes

    Parameters
    ----------
    X : np.ndarray
        features of the dataset
    y : np.ndarray
        labels of the dataset
    Tree : estimator
        estimator to fit and predict
    Returns
    -------
    results : dict
        contains 'Y_train', 'Y_test', 'Y_pred_test'
    """
    X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)
    reg = Tree()
    reg.fit(X_train, Y_train)
    # Y_pred_train = reg.predict(X_train, Y_train)
    Y_pred_test = reg.predict(X_test)
    results = {'Y_train': Y_train,
               'Y_test': Y_test,
               # 'Y_pred_train': Y_pred_train,
               'Y_pred_test': Y_pred_test}
    return results


class TestFit():
    """
    Test class for the .fit() function
    """

    def test_time(self):
        """Test the time for fitting

        Returns
        -------
        None
        """
        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)
        for name, Tree in OKTREES.items():
            reg = Tree()
            t0 = time.time()
            reg.fit(X_train, Y_train)
            fit_time = time.time() - t0
            assert fit_time < 100, f"Failed with {name}: 'fit_time' is over 100 seconds"

    def test_fit_fits(self):
        """Checks that using the .fit() function actually fit the estimator

        Returns
        -------
        None
        """
        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)
        for name, Tree in OKTREES.items():
            reg = Tree()
            with pytest.raises(NotFittedError):
                check_is_fitted(reg)
            reg.fit(X_train, Y_train)
            assert check_is_fitted(reg) is None, f"Failed with {name}: 'reg' should be fitted after fitting"


class TestPredict():
    """
    Test class for the .predict() function
    """

    def test_model_return_object(self):
        """Checks that our fitted_predicted_estimator returns the good object

        Returns
        -------
        None
        """
        for name, Tree in OKTREES.items():
            returned_OK3 = fitted_predicted_OK3(X, y, Tree)
            # Check the return object type
            assert isinstance(returned_OK3, dict), f'Failed with {name}:' \
                                                   f'"returned_IOKR" should be a dict, ' \
                                                   f'but instead is a {type(returned_OK3)}'
            # Check the length of the returned object
            assert len(returned_OK3) == 3, f'Failed with {name}:' \
                                           f'"returned_IOKR" should have a length of 3, ' \
                                           f'but instead it is {len(returned_OK3)}'

    def test_model_return_values(self):
        """Checks that 'Y_train', 'Y_test', 'Y_pred_test' from our fitted_predicted_estimator are
        non-empty, and np.ndarray

        Returns
        -------
        None
        """
        for name, Tree in OKTREES.items():
            returned_OK3 = fitted_predicted_OK3(X, y, Tree)
            # Check returned arrays' type
            assert returned_OK3['Y_train'].size != 0, f"Failed with {name}:'Y_train' is empty"
            assert returned_OK3['Y_test'].size != 0, f"Failed with {name}:'Y_test' is empty"
            assert returned_OK3['Y_pred_test'].size != 0, f"Failed with {name}:'Y_pred_test' is empty"
            assert isinstance(returned_OK3['Y_train'], np.ndarray), \
                f"Failed with {name}:'Y_train' should be a 'np.ndarray, but is {type(returned_OK3['Y_train'])}"
            assert isinstance(returned_OK3['Y_test'], np.ndarray), \
                f"Failed with {name}:'Y_test' should be a 'np.ndarray, but is {type(returned_OK3['Y_test'])}"
            assert isinstance(returned_OK3['Y_pred_test'], np.ndarray), \
                f"Failed with {name}:'Y_pred_test' should be a 'np.ndarray, but is {type(returned_OK3['Y_pred_test'])}"

    def test_time(self):
        """Test the time for predicting

        Returns
        -------
        None
        """
        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=42)
        for name, Tree in OKTREES.items():
            reg = Tree()
            reg.fit(X_train, Y_train)
            test_t0 = time.time()
            Y_pred_test = reg.predict(X=X_test)
            test_pred_time = time.time() - test_t0
            assert test_pred_time < 100, f'Failed with {name}:"test_pred_time" is over 100 seconds'

    def test_mse(self):
        """Checks the MSE score of the model

        Returns
        -------
        None
        """
        for name, Tree in OKTREES.items():
            fp_0K3 = fitted_predicted_OK3(X, y, Tree)
            test_mse = MSE(fp_0K3['Y_test'], fp_0K3['Y_pred_test'])
            test_rmse = test_mse**0.5
            threshold = 0
            assert test_mse > threshold, f'Failed with {name}: accuracy = {test_mse}, but threshold set to {threshold} '
            assert test_rmse > threshold, f'Failed with {name}: accuracy = {test_rmse}, but threshold set to {threshold} '

def test_X_y_inputation():
    """Checks the reaction of the estimator with bad inputation of X and y

    Returns
    -------
    None
    """
    for name, Tree in OKTREES.items():
        # ValueError
        with pytest.raises(ValueError):
            # Insert a np.nan into the X array
            Xt, yt = X, y
            Xt[1] = np.nan
            scores = fitted_predicted_OK3(Xt, yt, Tree)
        with pytest.raises(ValueError):
            # Insert a np.nan into the y array
            Xt, yt = X, y
            yt[1] = np.nan
            scores = fitted_predicted_OK3(Xt, yt, Tree)

        with pytest.raises(ValueError) as exception:
            # Insert a string into the X array
            Xt, yt = X, y
            Xt[1] = "A string"
            scores = fitted_predicted_OK3(Xt, yt, Tree)
            assert "could not convert string to float" in str(exception.value)

        # Test that it handles the case of: X is a string
        with pytest.raises(ValueError):
            msg = fitted_predicted_OK3('X', y, Tree)
            assert isinstance(msg, AssertionError)
            assert msg.args[0] == "X must be a Numpy array"
        # Test that it handles the case of: y is a string
        with pytest.raises(ValueError):
            msg = fitted_predicted_OK3(X, 'y', Tree)
            assert isinstance(msg, AssertionError)
            assert msg.args[0] == "y must be a Numpy array"


    '''For clfs
    def test_recall(self):
        """Test the recall score"""
        for name, Tree in OKTREES.items():
            fp_0K3 = fitted_predicted_OK3(X, y, Tree)
            recall_test = recall_score(fp_0K3['Y_test'], fp_0K3['Y_pred_test'], average="macro")
            threshold = 0
            assert recall_test > threshold, f'Failed with {name}: recall_test = {recall_test}, but threshold set to {threshold}'

    def test_precision(self):
        """Tests the precision score"""
        for name, Tree in OKTREES.items():
            fp_0K3 = fitted_predicted_OK3(X, y, Tree)
            precision_test = precision_score(fp_0K3['Y_test'], fp_0K3['Y_pred_test'], average="micro")
            threshold = 0
            assert precision_test > threshold, f'Failed with {name}: precision_test = {precision_test}, but threshold set to {threshold}'

    def test_f1_score(self):
        """Tests the F1_score"""
        for name, Tree in OKTREES.items():
            fp_0K3 = fitted_predicted_OK3(X, y, Tree)
            f1_test = f1_score(fp_0K3['Y_pred_test'], fp_0K3['Y_test'], average='micro')
            threshold = 0
            # Check f1 score range
            assert 1.0 >= f1_test >= 0.0, f"Failed with {name}: f1 score is of {f1_test}, should be between 0 and 1"
            # assert f1 score is enough
            assert f1_test > threshold, f'Failed with {name}: f1_test = {f1_test}, but threshold set to {threshold}'

    def test_accuracy_score(self):
        """Check accuracy of the model"""
        for name, Tree in OKTREES.items():
            fp_0K3 = fitted_predicted_OK3(X, y, Tree)
            accuracy = accuracy_score(fp_0K3['Y_test'], fp_0K3['Y_pred_test'])
            threshold = 0
            assert accuracy > threshold, f'Failed with {name}: accuracy = {accuracy}, but threshold set to {threshold} '
    '''


#def test_sklearn_check_estimator():
#    """test with check_estimator from sklearn"""
#    for name, Tree in OKTREES.items():
#        check_estimator(Tree())

# from os.path import join
# from sklearn.utils._testing import assert_array_equal
# from sklearn.utils._testing import assert_array_almost_equal
# from sklearn.utils._testing import assert_almost_equal
