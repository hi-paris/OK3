<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>OK3 package &mdash; OK3  documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="OK3.helpers package" href="OK3.helpers.html" />
    <link rel="prev" title="OK3" href="modules.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html">
            <img src="_static/LogoTelecom.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">OK3</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">OK3 package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#subpackages">Subpackages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="OK3.helpers.html">OK3.helpers package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#submodules">Submodules</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-OK3.base">OK3.base module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-OK3.kernel">OK3.kernel module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-OK3.structured_object">OK3.structured_object module</a></li>
<li class="toctree-l3"><a class="reference internal" href="#module-OK3">Module contents</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="setup.html">setup module</a></li>
<li class="toctree-l2"><a class="reference internal" href="tests.html">tests package</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">OK3</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="modules.html">OK3</a> &raquo;</li>
      <li>OK3 package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/OK3.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="ok3-package">
<h1>OK3 package<a class="headerlink" href="#ok3-package" title="Permalink to this headline"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="OK3.helpers.html">OK3.helpers package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="OK3.helpers.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="OK3.helpers.html#ok3-helpers-openmp-helpers-module">OK3.helpers.openmp_helpers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="OK3.helpers.html#module-OK3.helpers.pre_build_helpers">OK3.helpers.pre_build_helpers module</a></li>
<li class="toctree-l2"><a class="reference internal" href="OK3.helpers.html#module-OK3.helpers">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline"></a></h2>
</section>
<section id="module-OK3.base">
<span id="ok3-base-module"></span><h2>OK3.base module<a class="headerlink" href="#module-OK3.base" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="OK3.base.StructuredOutputMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.base.</span></span><span class="sig-name descname"><span class="pre">StructuredOutputMixin</span></span><a class="headerlink" href="#OK3.base.StructuredOutputMixin" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Mixin to mark estimators that support structured prediction.</p>
</dd></dl>

</section>
<section id="module-OK3.kernel">
<span id="ok3-kernel-module"></span><h2>OK3.kernel module<a class="headerlink" href="#module-OK3.kernel" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Gaussian_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Gaussian_Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Gaussian_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Gaussian_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Gaussian_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Gaussian_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Gaussian_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Gaussian_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Gaussian_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Gini_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Gini_Kernel</span></span><a class="headerlink" href="#OK3.kernel.Gini_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Mean_Dirac_Kernel" title="OK3.kernel.Mean_Dirac_Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Mean_Dirac_Kernel</span></code></a></p>
<p>Identique au ‘Mean_Dirac_Kernel’, mais permet de signaler que le décodage 
ne se fait pas parmi un candidates set mais est une recherche exhaustive.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objects_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objects_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Kernel.get_name">
<span class="sig-name descname"><span class="pre">get_name</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Kernel.get_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objects</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Laplacian_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Laplacian_Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Laplacian_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Laplacian_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Laplacian_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Laplacian_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Laplacian_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Laplacian_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Laplacian_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Linear_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Linear_Kernel</span></span><a class="headerlink" href="#OK3.kernel.Linear_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Linear_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Linear_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Linear_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Linear_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Linear_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Linear_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.MSE_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">MSE_Kernel</span></span><a class="headerlink" href="#OK3.kernel.MSE_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Linear_Kernel" title="OK3.kernel.Linear_Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Linear_Kernel</span></code></a></p>
<p>Similar to ‘Linear_Kernel’, but enable to flag that the decoding is done on
an exact solution and not within the set of candidates.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.kernel.Mean_Dirac_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.kernel.</span></span><span class="sig-name descname"><span class="pre">Mean_Dirac_Kernel</span></span><a class="headerlink" href="#OK3.kernel.Mean_Dirac_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Mean_Dirac_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Mean_Dirac_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Mean_Dirac_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Mean_Dirac_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.kernel.Mean_Dirac_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.kernel.Mean_Dirac_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-OK3.structured_object">
<span id="ok3-structured-object-module"></span><h2>OK3.structured_object module<a class="headerlink" href="#module-OK3.structured_object" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="OK3.structured_object.StructuredObject">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.structured_object.</span></span><span class="sig-name descname"><span class="pre">StructuredObject</span></span><a class="headerlink" href="#OK3.structured_object.StructuredObject" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.structured_object.StructuredObject.get_name">
<span class="sig-name descname"><span class="pre">get_name</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#OK3.structured_object.StructuredObject.get_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.structured_object.StructuredObject.is_equal_to">
<span class="sig-name descname"><span class="pre">is_equal_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.structured_object.StructuredObject.is_equal_to" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.structured_object.StructuredObject.similarity_with">
<span class="sig-name descname"><span class="pre">similarity_with</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.structured_object.StructuredObject.similarity_with" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-OK3">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-OK3" title="Permalink to this headline"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="OK3.ExtraOK3Regressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">ExtraOK3Regressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'random'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ccp_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.ExtraOK3Regressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.OK3Regressor" title="OK3._classes.OK3Regressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3._classes.OK3Regressor</span></code></a></p>
<p>An extremely randomized tree regressor.</p>
<p>Extra-trees differ from classic decision trees in the way they are built.
When looking for the best split to separate the samples of a node into two
groups, random splits are drawn for each of the <cite>max_features</cite> randomly
selected features and the best split among those is chosen. When
<cite>max_features</cite> is set 1, this amounts to building a totally random
decision tree.</p>
<p>Warning: Extra-trees should only be used within ensemble methods.</p>
<dl>
<dt>criterion<span class="classifier">{“mse”, “friedman_mse”, “mae”}, default=”mse”</span></dt><dd><p>The function to measure the quality of a split. Supported criteria
are “mse” for the mean squared error, which is equal to variance
reduction as feature selection criterion, and “mae” for the mean
absolute error.</p>
</dd>
<dt>splitter<span class="classifier">{“random”, “best”}, default=”random”</span></dt><dd><p>The strategy used to choose the split at each node. Supported
strategies are “best” to choose the best split and “random” to choose
the best random split.</p>
</dd>
<dt>max_depth<span class="classifier">int, default=None</span></dt><dd><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int or float, default=2</span></dt><dd><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_split</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_split</cite> is a fraction and
<cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</p></li>
</ul>
</dd>
<dt>min_samples_leaf<span class="classifier">int or float, default=1</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_leaf</cite> is a fraction and
<cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</p></li>
</ul>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, default=0.0</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_features<span class="classifier">int, float, {“auto”, “sqrt”, “log2”} or None, default=”auto”</span></dt><dd><p>The number of features to consider when looking for the best split:</p>
<ul class="simple">
<li><p>If int, then consider <cite>max_features</cite> features at each split.</p></li>
<li><p>If float, then <cite>max_features</cite> is a fraction and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</p></li>
<li><p>If “auto”, then <cite>max_features=n_features</cite>.</p></li>
<li><p>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</p></li>
<li><p>If “log2”, then <cite>max_features=log2(n_features)</cite>.</p></li>
<li><p>If None, then <cite>max_features=n_features</cite>.</p></li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>random_state<span class="classifier">int, RandomState instance, default=None</span></dt><dd><p>Used to pick randomly the <cite>max_features</cite> used at each split.
See <span class="xref std std-term">Glossary</span> for details.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, default=0.0</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>min_impurity_split<span class="classifier">float, (default=0)</span></dt><dd><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.19: </span><code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> has been deprecated in favor of
<code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> in 0.19. The default value of
<code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> has changed from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> instead.</p>
</div>
</dd>
<dt>max_leaf_nodes<span class="classifier">int, default=None</span></dt><dd><p>Grow a tree with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>ccp_alpha<span class="classifier">non-negative float, default=0.0</span></dt><dd><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code> will be chosen. By default, no pruning is performed. See
<span class="xref std std-ref">minimal_cost_complexity_pruning</span> for details.</p>
</dd>
<dt>kernel<span class="classifier">string, or tuple (string, params) or instance of the Kernel class, default=”linear”</span></dt><dd><p>The type of kernel to use to compare the output data. Changing this
parameter changes also implicitely the nature of the Hilbert space
in which the output data are embedded.
The string describes the type of Kernel to use (defined in Kernel.py), 
The optional params given are here to set particular parameters values
for the chosen kernel type.</p>
</dd>
</dl>
<dl>
<dt><a href="#id9"><span class="problematic" id="id10">max_features_</span></a><span class="classifier">int</span></dt><dd><p>The inferred value of max_features.</p>
</dd>
<dt><a href="#id11"><span class="problematic" id="id12">n_features_</span></a><span class="classifier">int</span></dt><dd><p>The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id13"><span class="problematic" id="id14">feature_importances_</span></a><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>Return impurity-based feature importances (the higher, the more
important the feature).</p>
<p>Warning: impurity-based feature importances can be misleading for
high cardinality features (many unique values). See
<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance()</span></code> as an alternative.</p>
</dd>
<dt><a href="#id15"><span class="problematic" id="id16">tree_</span></a><span class="classifier">Tree</span></dt><dd><p>The underlying Tree object. Please refer to
<code class="docutils literal notranslate"><span class="pre">help(sklearn.tree._tree.Tree)</span></code> for attributes of Tree object and
<span class="xref std std-ref">sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</span>
for basic usage of these attributes.</p>
</dd>
</dl>
<p>ExtraTreeClassifier : An extremely randomized tree classifier.
sklearn.ensemble.ExtraTreesClassifier : An extra-trees classifier.
sklearn.ensemble.ExtraTreesRegressor : An extra-trees regressor.</p>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<dl class="footnote brackets">
<dt class="label" id="id1"><span class="brackets">1</span></dt>
<dd><p>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”,
Machine Learning, 63(1), 3-42, 2006.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extra_tree</span> <span class="o">=</span> <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">extra_tree</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.33...</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.ExtraOKTreesRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">ExtraOKTreesRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ccp_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.ExtraOKTreesRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">OK3._forest.OKForestRegressor</span></code></p>
<p>An extra-trees regressor.</p>
<p>This class implements a meta estimator that fits a number of
randomized decision trees (a.k.a. extra-trees) on various sub-samples
of the dataset and uses averaging to improve the predictive accuracy
and control over-fitting.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl>
<dt>n_estimators<span class="classifier">int, default=100</span></dt><dd><p>The number of trees in the forest.</p>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.22: </span>The default value of <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> changed from 10 to 100
in 0.22.</p>
</div>
</dd>
<dt>criterion<span class="classifier">{“mse”}, default=”mse”</span></dt><dd><p>The function to measure the quality of a split. Supported criteria
are “mse” for the mean squared error, which is equal to variance
reduction as feature selection criterion</p>
</dd>
<dt>max_depth<span class="classifier">int, default=None</span></dt><dd><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int or float, default=2</span></dt><dd><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_split</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_split</cite> is a fraction and
<cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</p></li>
</ul>
</dd>
<dt>min_samples_leaf<span class="classifier">int or float, default=1</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_leaf</cite> is a fraction and
<cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</p></li>
</ul>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, default=0.0</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_features<span class="classifier">{“auto”, “sqrt”, “log2”}, int or float, default=”auto”</span></dt><dd><p>The number of features to consider when looking for the best split:</p>
<ul class="simple">
<li><p>If int, then consider <cite>max_features</cite> features at each split.</p></li>
<li><p>If float, then <cite>max_features</cite> is a fraction and
<cite>round(max_features * n_features)</cite> features are considered at each
split.</p></li>
<li><p>If “auto”, then <cite>max_features=n_features</cite>.</p></li>
<li><p>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</p></li>
<li><p>If “log2”, then <cite>max_features=log2(n_features)</cite>.</p></li>
<li><p>If None, then <cite>max_features=n_features</cite>.</p></li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>max_leaf_nodes<span class="classifier">int, default=None</span></dt><dd><p>Grow trees with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, default=0.0</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>min_impurity_split<span class="classifier">float, default=None</span></dt><dd><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
</dd>
<dt>bootstrap<span class="classifier">bool, default=False</span></dt><dd><p>Whether bootstrap samples are used when building trees. If False, the
whole dataset is used to build each tree.</p>
</dd>
<dt>oob_score<span class="classifier">bool, default=False</span></dt><dd><p>Whether to use out-of-bag samples to estimate the R^2 on unseen data.</p>
</dd>
<dt>n_jobs<span class="classifier">int, default=None</span></dt><dd><p>The number of jobs to run in parallel. <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">decision_path()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> are all parallelized over the
trees. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code>
context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span> for more details.</p>
</dd>
<dt>random_state<span class="classifier">int or RandomState, default=None</span></dt><dd><p>Controls 3 sources of randomness:</p>
<ul class="simple">
<li><p>the bootstrapping of the samples used when building trees
(if <code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>)</p></li>
<li><p>the sampling of the features to consider when looking for the best
split at each node (if <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">&lt;</span> <span class="pre">n_features</span></code>)</p></li>
<li><p>the draw of the splits for each of the <cite>max_features</cite></p></li>
</ul>
<p>See <span class="xref std std-term">Glossary</span> for details.</p>
</dd>
<dt>verbose<span class="classifier">int, default=0</span></dt><dd><p>Controls the verbosity when fitting and predicting.</p>
</dd>
<dt>warm_start<span class="classifier">bool, default=False</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See <span class="xref std std-term">the Glossary</span>.</p>
</dd>
<dt>ccp_alpha<span class="classifier">non-negative float, default=0.0</span></dt><dd><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code> will be chosen. By default, no pruning is performed. See
<span class="xref std std-ref">minimal_cost_complexity_pruning</span> for details.</p>
</dd>
<dt>max_samples<span class="classifier">int or float, default=None</span></dt><dd><p>If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul class="simple">
<li><p>If None (default), then draw <cite>X.shape[0]</cite> samples.</p></li>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples. Thus,
<cite>max_samples</cite> should be in the interval <cite>(0, 1)</cite>.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt><a href="#id17"><span class="problematic" id="id18">base_estimator_</span></a><span class="classifier">ExtraTreeRegressor</span></dt><dd><p>The child estimator template used to create the collection of fitted
sub-estimators.</p>
</dd>
<dt><a href="#id19"><span class="problematic" id="id20">estimators_</span></a><span class="classifier">list of DecisionTreeRegressor</span></dt><dd><p>The collection of fitted sub-estimators.</p>
</dd>
<dt><a href="#id21"><span class="problematic" id="id22">feature_importances_</span></a><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>The impurity-based feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance.</p>
<p>Warning: impurity-based feature importances can be misleading for
high cardinality features (many unique values). See
<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance()</span></code> as an alternative.</p>
</dd>
<dt><a href="#id23"><span class="problematic" id="id24">n_features_</span></a><span class="classifier">int</span></dt><dd><p>The number of features.</p>
</dd>
<dt><a href="#id25"><span class="problematic" id="id26">n_outputs_</span></a><span class="classifier">int</span></dt><dd><p>The number of outputs.</p>
</dd>
<dt><a href="#id27"><span class="problematic" id="id28">oob_score_</span></a><span class="classifier">float</span></dt><dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
</dd>
<dt><a href="#id29"><span class="problematic" id="id30">oob_prediction_</span></a><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Prediction computed with out-of-bag estimate on the training set.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
</dd>
</dl>
<p>sklearn.tree.ExtraTreeRegressor: Base estimator for this ensemble.
RandomForestRegressor: Ensemble regressor using trees with optimal splits.</p>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets">1</span></dt>
<dd><p>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”,
Machine Learning, 63(1), 3-42, 2006.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">ExtraOKTreesRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.2708...</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Gaussian_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Gaussian_Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Gaussian_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.Gaussian_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Gaussian_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Gaussian_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Gaussian_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Gaussian_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Gaussian_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Gini_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Gini_Kernel</span></span><a class="headerlink" href="#OK3.Gini_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Mean_Dirac_Kernel" title="OK3.kernel.Mean_Dirac_Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Mean_Dirac_Kernel</span></code></a></p>
<p>Identique au ‘Mean_Dirac_Kernel’, mais permet de signaler que le décodage 
ne se fait pas parmi un candidates set mais est une recherche exhaustive.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">obj1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">obj2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objects_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">objects_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Kernel.get_name">
<span class="sig-name descname"><span class="pre">get_name</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Kernel.get_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objects</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Laplacian_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Laplacian_Kernel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Laplacian_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.Laplacian_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Laplacian_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Laplacian_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Laplacian_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Laplacian_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Laplacian_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Linear_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Linear_Kernel</span></span><a class="headerlink" href="#OK3.Linear_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.Linear_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Linear_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Linear_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Linear_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Linear_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Linear_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.MSE_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">MSE_Kernel</span></span><a class="headerlink" href="#OK3.MSE_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Linear_Kernel" title="OK3.kernel.Linear_Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Linear_Kernel</span></code></a></p>
<p>Similar to ‘Linear_Kernel’, but enable to flag that the decoding is done on
an exact solution and not within the set of candidates.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.Mean_Dirac_Kernel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">Mean_Dirac_Kernel</span></span><a class="headerlink" href="#OK3.Mean_Dirac_Kernel" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#OK3.kernel.Kernel" title="OK3.kernel.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">OK3.kernel.Kernel</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.Mean_Dirac_Kernel.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">y1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y2</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Mean_Dirac_Kernel.evaluate" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Mean_Dirac_Kernel.get_Gram_matrix">
<span class="sig-name descname"><span class="pre">get_Gram_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y_1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">list_y_2</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Mean_Dirac_Kernel.get_Gram_matrix" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.Mean_Dirac_Kernel.get_sq_norms">
<span class="sig-name descname"><span class="pre">get_sq_norms</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">list_y</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.Mean_Dirac_Kernel.get_sq_norms" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.OK3Regressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">OK3Regressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">splitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'best'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ccp_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.OK3Regressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">OK3._classes.BaseKernelizedOutputTree</span></code></p>
<p>A decision tree regressor for the OK3 method.</p>
<dl>
<dt>criterion<span class="classifier">{“mse”}, default=”mse”</span></dt><dd><p>The function to measure the quality of a split. Supported criteria
are “mse” for the mean squared error, which is equal to variance
reduction as feature selection criterion and minimizes the L2 loss
using the mean of each terminal node, “friedman_mse”, which uses mean
squared error with Friedman’s improvement score for potential splits,
and “mae” for the mean absolute error, which minimizes the L1 loss
using the median of each terminal node.</p>
</dd>
<dt>splitter<span class="classifier">{“best”, “random”}, default=”best”</span></dt><dd><p>The strategy used to choose the split at each node. Supported
strategies are “best” to choose the best split and “random” to choose
the best random split.</p>
</dd>
<dt>max_depth<span class="classifier">int, default=None</span></dt><dd><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int or float, default=2</span></dt><dd><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_split</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_split</cite> is a fraction and
<cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</p></li>
</ul>
</dd>
<dt>min_samples_leaf<span class="classifier">int or float, default=1</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_leaf</cite> is a fraction and
<cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</p></li>
</ul>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, default=0.0</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_features<span class="classifier">int, float or {“auto”, “sqrt”, “log2”}, default=None</span></dt><dd><p>The number of features to consider when looking for the best split:</p>
<ul class="simple">
<li><p>If int, then consider <cite>max_features</cite> features at each split.</p></li>
<li><p>If float, then <cite>max_features</cite> is a fraction and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</p></li>
<li><p>If “auto”, then <cite>max_features=n_features</cite>.</p></li>
<li><p>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</p></li>
<li><p>If “log2”, then <cite>max_features=log2(n_features)</cite>.</p></li>
<li><p>If None, then <cite>max_features=n_features</cite>.</p></li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>random_state<span class="classifier">int, RandomState instance, default=None</span></dt><dd><p>Controls the randomness of the estimator. The features are always
randomly permuted at each split, even if <code class="docutils literal notranslate"><span class="pre">splitter</span></code> is set to
<code class="docutils literal notranslate"><span class="pre">&quot;best&quot;</span></code>. When <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">&lt;</span> <span class="pre">n_features</span></code>, the algorithm will
select <code class="docutils literal notranslate"><span class="pre">max_features</span></code> at random at each split before finding the best
split among them. But the best found split may vary across different
runs, even if <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>. That is the case, if the
improvement of the criterion is identical for several splits and one
split has to be selected at random. To obtain a deterministic behaviour
during fitting, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> has to be fixed to an integer.
See <span class="xref std std-term">Glossary</span> for details.</p>
</dd>
<dt>max_leaf_nodes<span class="classifier">int, default=None</span></dt><dd><p>Grow a tree with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, default=0.0</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>min_impurity_split<span class="classifier">float, (default=0)</span></dt><dd><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Deprecated since version 0.19: </span><code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> has been deprecated in favor of
<code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> in 0.19. The default value of
<code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> has changed from 1e-7 to 0 in 0.23 and it
will be removed in 0.25. Use <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> instead.</p>
</div>
</dd>
<dt>ccp_alpha<span class="classifier">non-negative float, default=0.0</span></dt><dd><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code> will be chosen. By default, no pruning is performed. See
<span class="xref std std-ref">minimal_cost_complexity_pruning</span> for details.</p>
</dd>
<dt>kernel<span class="classifier">string, or tuple (string, params) or instance of the Kernel class, default=”linear”</span></dt><dd><p>The type of kernel to use to compare the output data. Changing this
parameter changes also implicitely the nature of the Hilbert space
in which the output data are embedded.
The string describes the type of Kernel to use (defined in Kernel.py), 
The optional params given are here to set particular parameters values
for the chosen kernel type.</p>
</dd>
</dl>
<dl>
<dt><a href="#id31"><span class="problematic" id="id32">feature_importances_</span></a><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>The feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the
(normalized) total reduction of the criterion brought
by that feature. It is also known as the Gini importance <a href="#id33"><span class="problematic" id="id3">[4]_</span></a>.</p>
<p>Warning: impurity-based feature importances can be misleading for
high cardinality features (many unique values). See
<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance()</span></code> as an alternative.</p>
</dd>
<dt><a href="#id34"><span class="problematic" id="id35">max_features_</span></a><span class="classifier">int</span></dt><dd><p>The inferred value of max_features.</p>
</dd>
<dt><a href="#id36"><span class="problematic" id="id37">n_features_</span></a><span class="classifier">int</span></dt><dd><p>The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id38"><span class="problematic" id="id39">tree_</span></a><span class="classifier">Tree</span></dt><dd><p>The underlying Tree object. Please refer to
<code class="docutils literal notranslate"><span class="pre">help(sklearn.tree._tree.Tree)</span></code> for attributes of Tree object and
<span class="xref std std-ref">sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py</span>
for basic usage of these attributes.</p>
</dd>
<dt>leaves_preds<span class="classifier">array of shape (n_nodes, n_components),</span></dt><dd><p>where n_nodes is the number of nodes of the grown tree and
n_components is the number of values used to represent an output.</p>
<p>This array stores for each leaf of the tree, the decoded predictions in Y.</p>
</dd>
</dl>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<dl class="footnote brackets">
<dt class="label" id="id4"><span class="brackets">1</span></dt>
<dd><p>Pierre Geurts, Louis Wehenkel, Florence d’Alché-Buc. 
“Kernelizing the output of tree-based methods.”
Proc.  of the 23rd International Conference on Machine Learning, 
2006, United States.  pp.345–352,￿10.1145/1143844.1143888￿.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; from sklearn.datasets import load_diabetes
&gt;&gt;&gt; from sklearn.model_selection import cross_val_score
&gt;&gt;&gt; from ??? import OK3Regressor
&gt;&gt;&gt; X, y = load_diabetes(return_X_y=True)
&gt;&gt;&gt; regressor = OK3Regressor(random_state=0)
&gt;&gt;&gt; cross_val_score(regressor, X, y, cv=10)
...                    
...
array([-0.39..., -0.46...,  0.02...,  0.06..., -0.50...,
       0.16...,  0.11..., -0.73..., -0.30..., -0.00...])
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.OK3Regressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">check_input</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">X_idx_sorted</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'deprecated'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_ensemble</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Gram_y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.OK3Regressor.fit" title="Permalink to this definition"></a></dt>
<dd><p>Build a decision tree regressor from the training set (X, y).</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>The training input samples. Internally, it will be converted to
<code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> and if a sparse matrix is provided
to a sparse <code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code>.</p>
</dd>
<dt>y<span class="classifier">array-like of shape (n_samples,) or (n_samples, n_outputs)</span></dt><dd><p>The target values (real numbers). Use <code class="docutils literal notranslate"><span class="pre">dtype=np.float64</span></code> and
<code class="docutils literal notranslate"><span class="pre">order='C'</span></code> for maximum efficiency.</p>
</dd>
<dt>sample_weight<span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node.</p>
</dd>
<dt>check_input<span class="classifier">bool, default=True</span></dt><dd><p>Allow to bypass several input checking.
Don’t use this parameter unless you know what you do.</p>
</dd>
<dt>X_idx_sorted<span class="classifier">deprecated, default=”deprecated”</span></dt><dd><p>This parameter is deprecated and has no effect.
It will be removed in v0.26.</p>
</dd>
<dt>kernel<span class="classifier">string, or tuple (string, params) or instance of the Kernel class, default=”linear”</span></dt><dd><p>The type of kernel to use to compare the output data. Changing this
parameter changes also implicitely the nature of the Hilbert space
in which the output data are embedded.
The string describes the type of Kernel to use (defined in Kernel.py), 
The optional params given are here to set particular parameters values
for the chosen kernel type.
This parameter can be set also here in the fit method instead of __init__.</p>
</dd>
</dl>
<dl class="simple">
<dt>self<span class="classifier">OK3Regressor</span></dt><dd><p>Fitted estimator.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.RandomOKForestRegressor">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">RandomOKForestRegressor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">criterion</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mse'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_features</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bootstrap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">oob_score</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ccp_alpha</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_samples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.RandomOKForestRegressor" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">OK3._forest.OKForestRegressor</span></code></p>
<p>A random ok-forest regressor.</p>
<p>A random forest is a meta estimator that fits a number of
decision trees on various sub-samples of the dataset and uses averaging
to improve the predictive accuracy and control over-fitting.
The sub-sample size is controlled with the <cite>max_samples</cite> parameter if
<cite>bootstrap=True</cite> (default), otherwise the whole dataset is used to build
each tree.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl>
<dt>n_estimators<span class="classifier">int, default=100</span></dt><dd><p>The number of trees in the forest.</p>
</dd>
<dt>criterion<span class="classifier">{“mse”}, default=”mse”</span></dt><dd><p>The function to measure the quality of a split. Supported criteria
are “mse” for the mean squared error, which is equal to variance
reduction as feature selection criterion</p>
</dd>
<dt>max_depth<span class="classifier">int, default=None</span></dt><dd><p>The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int or float, default=2</span></dt><dd><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_split</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_split</cite> is a fraction and
<cite>ceil(min_samples_split * n_samples)</cite> are the minimum
number of samples for each split.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.18: </span>Added float values for fractions.</p>
</div>
</dd>
<dt>min_samples_leaf<span class="classifier">int or float, default=1</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_leaf</cite> is a fraction and
<cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum
number of samples for each node.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 0.18: </span>Added float values for fractions.</p>
</div>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, default=0.0</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_features<span class="classifier">{“auto”, “sqrt”, “log2”}, int or float, default=”auto”</span></dt><dd><p>The number of features to consider when looking for the best split:</p>
<ul class="simple">
<li><p>If int, then consider <cite>max_features</cite> features at each split.</p></li>
<li><p>If float, then <cite>max_features</cite> is a fraction and
<cite>round(max_features * n_features)</cite> features are considered at each
split.</p></li>
<li><p>If “auto”, then <cite>max_features=n_features</cite>.</p></li>
<li><p>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</p></li>
<li><p>If “log2”, then <cite>max_features=log2(n_features)</cite>.</p></li>
<li><p>If None, then <cite>max_features=n_features</cite>.</p></li>
</ul>
<p>Note: the search for a split does not stop until at least one
valid partition of the node samples is found, even if it requires to
effectively inspect more than <code class="docutils literal notranslate"><span class="pre">max_features</span></code> features.</p>
</dd>
<dt>max_leaf_nodes<span class="classifier">int, default=None</span></dt><dd><p>Grow trees with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, default=0.0</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>min_impurity_split<span class="classifier">float, default=None</span></dt><dd><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
</dd>
<dt>bootstrap<span class="classifier">bool, default=True</span></dt><dd><p>Whether bootstrap samples are used when building trees. If False, the
whole dataset is used to build each tree.</p>
</dd>
<dt>oob_score<span class="classifier">bool, default=False</span></dt><dd><p>whether to use out-of-bag samples to estimate
the R^2 on unseen data.</p>
</dd>
<dt>n_jobs<span class="classifier">int, default=None</span></dt><dd><p>The number of jobs to run in parallel. <code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code>, <code class="xref py py-meth docutils literal notranslate"><span class="pre">predict()</span></code>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">decision_path()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> are all parallelized over the
trees. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code>
context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span> for more details.</p>
</dd>
<dt>random_state<span class="classifier">int or RandomState, default=None</span></dt><dd><p>Controls both the randomness of the bootstrapping of the samples used
when building trees (if <code class="docutils literal notranslate"><span class="pre">bootstrap=True</span></code>) and the sampling of the
features to consider when looking for the best split at each node
(if <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">&lt;</span> <span class="pre">n_features</span></code>).
See <span class="xref std std-term">Glossary</span> for details.</p>
</dd>
<dt>verbose<span class="classifier">int, default=0</span></dt><dd><p>Controls the verbosity when fitting and predicting.</p>
</dd>
<dt>warm_start<span class="classifier">bool, default=False</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See <span class="xref std std-term">the Glossary</span>.</p>
</dd>
<dt>ccp_alpha<span class="classifier">non-negative float, default=0.0</span></dt><dd><p>Complexity parameter used for Minimal Cost-Complexity Pruning. The
subtree with the largest cost complexity that is smaller than
<code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code> will be chosen. By default, no pruning is performed. See
<span class="xref std std-ref">minimal_cost_complexity_pruning</span> for details.</p>
</dd>
<dt>max_samples<span class="classifier">int or float, default=None</span></dt><dd><p>If bootstrap is True, the number of samples to draw from X
to train each base estimator.</p>
<ul class="simple">
<li><p>If None (default), then draw <cite>X.shape[0]</cite> samples.</p></li>
<li><p>If int, then draw <cite>max_samples</cite> samples.</p></li>
<li><p>If float, then draw <cite>max_samples * X.shape[0]</cite> samples. Thus,
<cite>max_samples</cite> should be in the interval <cite>(0, 1)</cite>.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt><a href="#id40"><span class="problematic" id="id41">base_estimator_</span></a><span class="classifier">DecisionTreeRegressor</span></dt><dd><p>The child estimator template used to create the collection of fitted
sub-estimators.</p>
</dd>
<dt><a href="#id42"><span class="problematic" id="id43">estimators_</span></a><span class="classifier">list of DecisionTreeRegressor</span></dt><dd><p>The collection of fitted sub-estimators.</p>
</dd>
<dt><a href="#id44"><span class="problematic" id="id45">feature_importances_</span></a><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>The impurity-based feature importances.
The higher, the more important the feature.
The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance.</p>
<p>Warning: impurity-based feature importances can be misleading for
high cardinality features (many unique values). See
<code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance()</span></code> as an alternative.</p>
</dd>
<dt><a href="#id46"><span class="problematic" id="id47">n_features_</span></a><span class="classifier">int</span></dt><dd><p>The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id48"><span class="problematic" id="id49">n_outputs_</span></a><span class="classifier">int</span></dt><dd><p>The number of outputs when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id50"><span class="problematic" id="id51">oob_score_</span></a><span class="classifier">float</span></dt><dd><p>Score of the training dataset obtained using an out-of-bag estimate.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
</dd>
<dt><a href="#id52"><span class="problematic" id="id53">oob_prediction_</span></a><span class="classifier">ndarray of shape (n_samples,)</span></dt><dd><p>Prediction computed with out-of-bag estimate on the training set.
This attribute exists only when <code class="docutils literal notranslate"><span class="pre">oob_score</span></code> is True.</p>
</dd>
</dl>
<p>OK3Regressor, ExtraOKTreesRegressor</p>
<p>The default values for the parameters controlling the size of the trees
(e.g. <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) lead to fully grown and
unpruned trees which can potentially be very large on some data sets. To
reduce memory consumption, the complexity and size of the trees should be
controlled by setting those parameter values.</p>
<p>The features are always randomly permuted at each split. Therefore,
the best found split may vary, even with the same training data,
<code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code> and <code class="docutils literal notranslate"><span class="pre">bootstrap=False</span></code>, if the improvement
of the criterion is identical for several splits enumerated during the
search of the best split. To obtain a deterministic behaviour during
fitting, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> has to be fixed.</p>
<p>The default value <code class="docutils literal notranslate"><span class="pre">max_features=&quot;auto&quot;</span></code> uses <code class="docutils literal notranslate"><span class="pre">n_features</span></code>
rather than <code class="docutils literal notranslate"><span class="pre">n_features</span> <span class="pre">/</span> <span class="pre">3</span></code>. The latter was originally suggested in
[1], whereas the former was more recently justified empirically in [2].</p>
<dl class="footnote brackets">
<dt class="label" id="id5"><span class="brackets">1</span></dt>
<dd><ol class="upperalpha simple" start="12">
<li><p>Breiman, “Random Forests”, Machine Learning, 45(1), 5-32, 2001.</p></li>
</ol>
</dd>
<dt class="label" id="id6"><span class="brackets">2</span></dt>
<dd><p>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized
trees”, Machine Learning, 63(1), 3-42, 2006.</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                       <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">RandomOKForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">RandomForestRegressor(...)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]))</span>
<span class="go">[-8.32987858]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">RandomOKTreesEmbedding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_estimators</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_samples_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_weight_fraction_leaf</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_leaf_nodes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_decrease</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_impurity_split</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse_output</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_jobs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">warm_start</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'linear'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.RandomOKTreesEmbedding" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">OK3._forest.BaseOKForest</span></code></p>
<p>An ensemble of totally random trees.</p>
<p>An unsupervised transformation of a dataset to a high-dimensional
sparse representation. A datapoint is coded according to which leaf of
each tree it is sorted into. Using a one-hot encoding of the leaves,
this leads to a binary coding with as many ones as there are trees in
the forest.</p>
<p>The dimensionality of the resulting representation is
<code class="docutils literal notranslate"><span class="pre">n_out</span> <span class="pre">&lt;=</span> <span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">max_leaf_nodes</span></code>. If <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span> <span class="pre">==</span> <span class="pre">None</span></code>,
the number of leaf nodes is at most <code class="docutils literal notranslate"><span class="pre">n_estimators</span> <span class="pre">*</span> <span class="pre">2</span> <span class="pre">**</span> <span class="pre">max_depth</span></code>.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl>
<dt>n_estimators<span class="classifier">int, default=100</span></dt><dd><p>Number of trees in the forest.</p>
</dd>
<dt>max_depth<span class="classifier">int, default=5</span></dt><dd><p>The maximum depth of each tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than
min_samples_split samples.</p>
</dd>
<dt>min_samples_split<span class="classifier">int or float, default=2</span></dt><dd><p>The minimum number of samples required to split an internal node:</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_split</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_split</cite> is a fraction and
<cite>ceil(min_samples_split * n_samples)</cite> is the minimum
number of samples for each split.</p></li>
</ul>
</dd>
<dt>min_samples_leaf<span class="classifier">int or float, default=1</span></dt><dd><p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.  This may have the effect of smoothing the model,
especially in regression.</p>
<ul class="simple">
<li><p>If int, then consider <cite>min_samples_leaf</cite> as the minimum number.</p></li>
<li><p>If float, then <cite>min_samples_leaf</cite> is a fraction and
<cite>ceil(min_samples_leaf * n_samples)</cite> is the minimum
number of samples for each node.</p></li>
</ul>
</dd>
<dt>min_weight_fraction_leaf<span class="classifier">float, default=0.0</span></dt><dd><p>The minimum weighted fraction of the sum total of weights (of all
the input samples) required to be at a leaf node. Samples have
equal weight when sample_weight is not provided.</p>
</dd>
<dt>max_leaf_nodes<span class="classifier">int, default=None</span></dt><dd><p>Grow trees with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</p>
</dd>
<dt>min_impurity_decrease<span class="classifier">float, default=0.0</span></dt><dd><p>A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.</p>
<p>The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</dd>
<dt>min_impurity_split<span class="classifier">float, default=None</span></dt><dd><p>Threshold for early stopping in tree growth. A node will split
if its impurity is above the threshold, otherwise it is a leaf.</p>
</dd>
<dt>sparse_output<span class="classifier">bool, default=True</span></dt><dd><p>Whether or not to return a sparse CSR matrix, as default behavior,
or to return a dense array compatible with dense pipeline operators.</p>
</dd>
<dt>n_jobs<span class="classifier">int, default=None</span></dt><dd><p>The number of jobs to run in parallel. <a class="reference internal" href="#OK3.RandomOKTreesEmbedding.fit" title="OK3.RandomOKTreesEmbedding.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">fit()</span></code></a>, <a class="reference internal" href="#OK3.RandomOKTreesEmbedding.transform" title="OK3.RandomOKTreesEmbedding.transform"><code class="xref py py-meth docutils literal notranslate"><span class="pre">transform()</span></code></a>,
<code class="xref py py-meth docutils literal notranslate"><span class="pre">decision_path()</span></code> and <code class="xref py py-meth docutils literal notranslate"><span class="pre">apply()</span></code> are all parallelized over the
trees. <code class="docutils literal notranslate"><span class="pre">None</span></code> means 1 unless in a <code class="xref py py-obj docutils literal notranslate"><span class="pre">joblib.parallel_backend</span></code>
context. <code class="docutils literal notranslate"><span class="pre">-1</span></code> means using all processors. See <span class="xref std std-term">Glossary</span> for more details.</p>
</dd>
<dt>random_state<span class="classifier">int or RandomState, default=None</span></dt><dd><p>Controls the generation of the random <cite>y</cite> used to fit the trees
and the draw of the splits for each feature at the trees’ nodes.
See <span class="xref std std-term">Glossary</span> for details.</p>
</dd>
<dt>verbose<span class="classifier">int, default=0</span></dt><dd><p>Controls the verbosity when fitting and predicting.</p>
</dd>
<dt>warm_start<span class="classifier">bool, default=False</span></dt><dd><p>When set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, reuse the solution of the previous call to fit
and add more estimators to the ensemble, otherwise, just fit a whole
new forest. See <span class="xref std std-term">the Glossary</span>.</p>
</dd>
</dl>
<dl class="simple">
<dt><a href="#id54"><span class="problematic" id="id55">base_estimator_</span></a><span class="classifier">DecisionTreeClassifier instance</span></dt><dd><p>The child estimator template used to create the collection of fitted
sub-estimators.</p>
</dd>
<dt><a href="#id56"><span class="problematic" id="id57">estimators_</span></a><span class="classifier">list of DecisionTreeClassifier instances</span></dt><dd><p>The collection of fitted sub-estimators.</p>
</dd>
<dt><a href="#id58"><span class="problematic" id="id59">feature_importances_</span></a><span class="classifier">ndarray of shape (n_features,)</span></dt><dd><p>The feature importances (the higher, the more important the feature).</p>
</dd>
<dt><a href="#id60"><span class="problematic" id="id61">n_features_</span></a><span class="classifier">int</span></dt><dd><p>The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id62"><span class="problematic" id="id63">n_outputs_</span></a><span class="classifier">int</span></dt><dd><p>The number of outputs when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</p>
</dd>
<dt><a href="#id64"><span class="problematic" id="id65">one_hot_encoder_</span></a><span class="classifier">OneHotEncoder instance</span></dt><dd><p>One-hot encoder used to create the sparse embedding.</p>
</dd>
</dl>
<dl class="footnote brackets">
<dt class="label" id="id7"><span class="brackets">1</span></dt>
<dd><p>P. Geurts, D. Ernst., and L. Wehenkel, “Extremely randomized trees”,
Machine Learning, 63(1), 3-42, 2006.</p>
</dd>
<dt class="label" id="id8"><span class="brackets">2</span></dt>
<dd><p>Moosmann, F. and Triggs, B. and Jurie, F.  “Fast discriminative
visual codebooks using randomized clustering forests”
NIPS 2007</p>
</dd>
</dl>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomTreesEmbedding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random_trees</span> <span class="o">=</span> <span class="n">RandomTreesEmbedding</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">n_estimators</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;gaussian&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_sparse_embedding</span> <span class="o">=</span> <span class="n">random_trees</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_sparse_embedding</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[0., 1., 1., 0., 1., 0., 0., 1., 1., 0.],</span>
<span class="go">       [0., 1., 1., 0., 1., 0., 0., 1., 1., 0.],</span>
<span class="go">       [0., 1., 0., 1., 0., 1., 0., 1., 0., 1.],</span>
<span class="go">       [1., 0., 1., 0., 1., 0., 1., 0., 1., 0.],</span>
<span class="go">       [0., 1., 1., 0., 1., 0., 0., 1., 1., 0.]])</span>
</pre></div>
</div>
<dl class="py attribute">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding.criterion">
<span class="sig-name descname"><span class="pre">criterion</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'mse'</span></em><a class="headerlink" href="#OK3.RandomOKTreesEmbedding.criterion" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.RandomOKTreesEmbedding.fit" title="Permalink to this definition"></a></dt>
<dd><p>Fit estimator.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>The input samples. Use <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code> for maximum efficiency.</p>
</dd>
<dt>y<span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
<dt>sample_weight<span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
</dd>
</dl>
<p>self : object</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding.fit_transform">
<span class="sig-name descname"><span class="pre">fit_transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.RandomOKTreesEmbedding.fit_transform" title="Permalink to this definition"></a></dt>
<dd><p>Fit estimator and transform dataset.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>Input data used to build forests. Use <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> for
maximum efficiency.</p>
</dd>
<dt>y<span class="classifier">Ignored</span></dt><dd><p>Not used, present for API consistency by convention.</p>
</dd>
<dt>sample_weight<span class="classifier">array-like of shape (n_samples,), default=None</span></dt><dd><p>Sample weights. If None, then samples are equally weighted. Splits
that would create child nodes with net zero or negative weight are
ignored while searching for a split in each node. In the case of
classification, splits are also ignored if they would result in any
single class carrying a negative weight in either child node.</p>
</dd>
</dl>
<dl class="simple">
<dt>X_transformed<span class="classifier">sparse matrix of shape (n_samples, n_out)</span></dt><dd><p>Transformed dataset.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding.max_features">
<span class="sig-name descname"><span class="pre">max_features</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">1</span></em><a class="headerlink" href="#OK3.RandomOKTreesEmbedding.max_features" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.RandomOKTreesEmbedding.transform">
<span class="sig-name descname"><span class="pre">transform</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.RandomOKTreesEmbedding.transform" title="Permalink to this definition"></a></dt>
<dd><p>Transform dataset.</p>
<dl class="simple">
<dt>X<span class="classifier">{array-like, sparse matrix} of shape (n_samples, n_features)</span></dt><dd><p>Input data to be transformed. Use <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> for maximum
efficiency. Sparse matrices are also supported, use sparse
<code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> for maximum efficiency.</p>
</dd>
</dl>
<dl class="simple">
<dt>X_transformed<span class="classifier">sparse matrix of shape (n_samples, n_out)</span></dt><dd><p>Transformed dataset.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.StructuredObject">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">StructuredObject</span></span><a class="headerlink" href="#OK3.StructuredObject" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="OK3.StructuredObject.get_name">
<span class="sig-name descname"><span class="pre">get_name</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#OK3.StructuredObject.get_name" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.StructuredObject.is_equal_to">
<span class="sig-name descname"><span class="pre">is_equal_to</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.StructuredObject.is_equal_to" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="OK3.StructuredObject.similarity_with">
<span class="sig-name descname"><span class="pre">similarity_with</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">other</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#OK3.StructuredObject.similarity_with" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="OK3.StructuredOutputMixin">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">OK3.</span></span><span class="sig-name descname"><span class="pre">StructuredOutputMixin</span></span><a class="headerlink" href="#OK3.StructuredOutputMixin" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Mixin to mark estimators that support structured prediction.</p>
</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="modules.html" class="btn btn-neutral float-left" title="OK3" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="OK3.helpers.html" class="btn btn-neutral float-right" title="OK3.helpers package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Pierre Geurts, Louis Wehenkel, Florence d&#39;Alché-Buc, Gaëtan Brison, Awais Sani, Danaël Schlewer-Becker.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>